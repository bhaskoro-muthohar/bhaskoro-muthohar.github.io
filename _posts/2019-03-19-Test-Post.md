---
layout: post
title: "Analyzing why people quit their job and who will quit next. Using Python and Machine Learning, Decision Tree Algorithm."
categories:
  - Post Formats
tags:
  - Data Analyst
  - Machine Learning
---

#Introduction

According to the article by Balance Articles, employees jump across jobs and roles for averagely 12 times during their lifetime career. Shocking! Imagine what happened to all of those billions of dollars wasted put by the Multinational Companies (MNCs) to retain the employees.

Therefore, managing employee attrition effectively and efficiently is very important. New employees will spend lots of time and money to train and hire them which could otherwise be reallocated in another investment. In fact, this has been a big concern for IBM HR Professionals that IBM is investing billions of dollars in Watson to predict flight risk and win employee attrition. Surely this means knowing why employee quits is a great beginning to attract and retain talents.

In conclusion,it is very important to derive a data driven decision making to understand employees leave to reduce turnover rate, save hiring/training cost and maximize work productivity. All of these translate into great profit for the years ahead.

I have done some analysis using Python and one of Machine Learning algorithm to find out why people leave their job and who the next potential employees that predicted will leave the job. Here we go! (Ba Dum Tss!)

#**1. Understanding the dataset**

The dataset comes from my repo [here](https://github.com/bhaskoro-muthohar/DataScienceLearning/blob/master/HR_comma_sep.csv) with csv (coma seperated value) format. The metadata includes the following features: Employee satisfaction level, Last Evaluation, Number of Projects, Average Monthly Hours, Time Spent at the Company, Whether they have had a work accident, Whether they have had a promotion in the last 5 years, Departments, Salary, Whether the employee has left.

Let us start our journey by importing the csv file into Pandas Dataframe.

```python
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)



df = pd.read_csv('https://raw.githubusercontent.com/bhaskoro-muthohar/DataScienceLearning/master/HR_comma_sep.csv')

```

#**2. Viewing the data**

Let us just glimpse on the quick and dirty sanity test at the data below with a simple code.
```python
print("This is Head")
print(df.head())


print('This is Tail')

print(df.tail())

```
![image](https://media.licdn.com/dms/image/C5112AQHEiyeca_S2Ow/article-inline_image-shrink_1000_1488/0?e=1580342400&v=beta&t=c1gTgNo-qVyvgU1mJOvrJ5x9jCzxnJdSWVQGxohsV0c)

First, to understand the quick outlook of our dataset, let us describe the dataset. We will transpose it to put the features as rows for better view.
```python
df.describe().T
```
![image](https://media.licdn.com/dms/image/C5112AQFIQ77xoVd6nA/article-inline_image-shrink_1000_1488/0?e=1580342400&v=beta&t=TZxaGyaCMJFiUxHH4Qb1dgUwXKUtTUmej47OH4s046g)

This will describe all of the numerical features with their aggregated values (counts, means, etc). From here we could see that everything looks good: full count values, no null, and logical distributed values. One interesting value is the max average monthly hours: 310 hours. Wow! That means somebody is working 15 hours per weekday. This guy is surely a workholic.

We then can describe the non numerical values by including the datatype ‘object’ for parameter. include=[‘object’]
```python
df.describe(include=['object'])
```
![image](https://media.licdn.com/dms/image/C5112AQHT18dsCtZstQ/article-inline_image-shrink_1000_1488/0?e=1580342400&v=beta&t=f4oc35eh3JT9EPqRQJ_xSKpqwEXNeLhMoR17HI4dnSE)

The sales here means the department that the employees are working on and the salary indicates “top”,”medium”,”low”. OK, all datas seems clean. We will proced.

#**3. Data Exploration**

##***Importing Matplotlib and Seaborn for Story Telling***
```python
# Import seaborn and matplotlib with matplotlib inline
import seaborn as sns
import matplotlib.pyplot as plt

%matplotlib inline
```
After importing seaborn and matplotlib, let us get the counts of people that left or stayed. We will visualize it in a simple matplotlib pie chart.

Let us generate multiple plot distribution for each leaving and staying employees, then combine it with Matplotlib Figure. This code will be a bit long as we are inserting 10 subplots (5 rows, 2 columns). But the visualization is really valuable to discover the trend and discrepancy among those who left and stayed. Hence the story telling!
```python
#make seperated list for satisfaction level
x1 = list(leftdf['satisfaction_level'])
x2 = list(notleftdf['satisfaction_level'])


#make seperated list for last evaluation
x3 = list(leftdf['last_evaluation'])
x4 = list(notleftdf['last_evaluation'])


#make seperated list for number project
x5 = list(leftdf['number_project'])
x6 = list(notleftdf['number_project'])


#make seperated list for average monthly hours
x7 = list(leftdf['average_montly_hours'])
x8 = list(notleftdf['average_montly_hours'])


#make seperated list for time spent company
x9 = list(leftdf['time_spend_company'])
x10 = list(notleftdf['time_spend_company'])



#assign color and names
colors = ['#E69F00', '#56B4E9']
names = ['leaving', 'stay']


# Make the histogram using a list of lists
#Normalize and assign colors and names
plt.subplot(511)
plt.hist([x1,x2], bins=12, normed=True, color=colors, label=names)
#plot formatting
plt.legend()
plt.xlabel('satisfaction level')
plt.ylabel('normalized value')


# Make the histogram using a list of lists
#Normalize and assign colors and names
plt.subplot(512)
plt.hist([x3,x4], bins=12, normed=True, color=colors, label=names)
#plot formatting
plt.legend()
plt.xlabel('last evaluation')
plt.ylabel('normalized value')


# Make the histogram using a list of lists
#Normalize and assign colors and names
plt.subplot(513)
plt.hist([x5,x6], bins=12, normed=True, color=colors, label=names)
#plot formatting
plt.legend()
plt.xlabel('number projects')
plt.ylabel('normalized value')


# Make the histogram using a list of lists
#Normalize and assign colors and names
plt.subplot(514)
plt.hist([x7,x8], bins=12, normed=True, color=colors, label=names)
#plot formatting
plt.legend()
plt.xlabel('average monthly hours')
plt.ylabel('normalized value')


# Make the histogram using a list of lists
#Normalize and assign colors and names
plt.subplot(515)
plt.hist([x9,x10], bins=12, normed=True, color=colors, label=names)
#plot formatting
plt.legend()
plt.xlabel('time spent')
plt.ylabel('normalized value')


plt.subplots_adjust(top=11 ,bottom=10)
plt.tight_layout()

plt.show()
```
![image](https://media.licdn.com/dms/image/C5112AQHPdaG5a7rJGg/article-inline_image-shrink_1000_1488/0?e=1580342400&v=beta&t=rS-JZxQX9C9yr0XZv0XnS299ZikYzT2wjl1vGeXa1e8)

Now, what could we learn from this?

##***Insights: Profile of the people who left***

⋅⋅*Satisfaction_level = People who left tends to had low satisfaction_level, but there is some people who very satisfied with their job and still left the job.
⋅⋅*last_evaluation = High and low which might indicate over achiever and under achiever that leaves the companies. If this is true, that means employees left for two reasons: that they feel they could not channel their talents or motivation well or that they are motivated and apply for better career opportunities.
⋅⋅*Number_project = Most have 2 projects. Maybe unlike the distribution of the staying employees who have 3–4 projects. We might want to compare this further with the average_monthly_hours and viewed whether there is a Simpson Paradox ongoing where the insights changed as we consider other confound variables. We also need to compare further with the size and nature of the project.
⋅⋅*average_monthly_hours = It has either large or not so much average worked hours. This is unique as maybe the employees are getting too much or too less engaged within their company.
⋅⋅*time_spend_company = Some of them spend less time than the employees who stay, we might want to assume that they are less engaged with their workload. Combined with average_monthly_hours, this is a likely assumption.
⋅⋅*Work_accident Does not have much work accidents
⋅⋅*promotion_last_5years Lot less not promoted
⋅⋅*sales Does not differ much
⋅⋅*salary Most of them are at the lower level salary (low)
